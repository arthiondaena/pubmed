{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96734f08",
   "metadata": {},
   "source": [
    "\n",
    "# PubMed API Script\n",
    "\n",
    "This Jupyter notebook demonstrates how to use the PubMed API to fetch and process academic papers. \n",
    "The script includes functions for querying PubMed, fetching metadata, and identifying authors based on affiliations.\n",
    "\n",
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f45f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bd2bee",
   "metadata": {},
   "source": [
    "\n",
    "## Function Definitions\n",
    "\n",
    "The following section contains functions for:\n",
    "- Querying the PubMed API\n",
    "- Parsing XML responses\n",
    "- Processing and categorizing papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9124e5",
   "metadata": {},
   "source": [
    "### Construct Query URLs\n",
    "The `mkquery` function helps in constructing a URL with query parameters for API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3c0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkquery(base_url: str, params: Dict[str, str]) -> str:\n",
    "    query = \"&\".join(f\"{key}={value}\" for key, value in params.items())\n",
    "    return f\"{base_url}?{query}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5470711",
   "metadata": {},
   "source": [
    "### Fetch XML Data\n",
    "The `getXmlFromURL` function sends a request to the PubMed API and parses the XML response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c055fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXmlFromURL(base_url: str, params: Dict[str, str]) -> ET.Element:\n",
    "    response = requests.get(mkquery(base_url, params))\n",
    "    response.raise_for_status()\n",
    "    return ET.fromstring(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efcd799",
   "metadata": {},
   "source": [
    "### Fetch Paper IDs\n",
    "The `fetch_paper_ids` function retrieves PubMed IDs for papers matching a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e75da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_paper_ids(query: str, max_results: int = 100) -> Tuple[List[str], str, str]:\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'term': query,\n",
    "        'retmax': str(max_results),\n",
    "        'usehistory': 'y'\n",
    "    }\n",
    "    root = getXmlFromURL(BASEURL_SRCH, params)\n",
    "    ids = [id_node.text for id_node in root.findall('.//Id')]\n",
    "    query_key = root.findtext('.//QueryKey')\n",
    "    web_env = root.findtext('.//WebEnv')\n",
    "    return ids, query_key, web_env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f448f0e",
   "metadata": {},
   "source": [
    "### Fetch Paper Details\n",
    "The `fetch_paper_details` function retrieves detailed information about the papers using PubMed IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9416fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_paper_details(query_key: str, web_env: str, batch_size: int = 10) -> List[Dict]:\n",
    "    params = {\n",
    "        'db': 'pubmed',\n",
    "        'query_key': query_key,\n",
    "        'WebEnv': web_env,\n",
    "        'retmax': str(batch_size),\n",
    "        'retmode': 'xml'\n",
    "    }\n",
    "    root = getXmlFromURL(BASEURL_FTCH, params)\n",
    "    papers = []\n",
    "\n",
    "    for article in root.iter('PubmedArticle'):\n",
    "        paper = {\n",
    "            'PubmedID': article.findtext('.//PMID'),\n",
    "            'Title': article.findtext('.//ArticleTitle'),\n",
    "            'PublicationDate': article.findtext('.//PubDate/Year'),\n",
    "            'Authors': [],\n",
    "            'Affiliations': []\n",
    "        }\n",
    "        for author in article.findall('.//Author'):\n",
    "            name = f\"{author.findtext('ForeName', '')} {author.findtext('LastName', '')}\".strip()\n",
    "            affiliation = author.findtext('.//Affiliation')\n",
    "            if name and affiliation:\n",
    "                paper['Authors'].append(name)\n",
    "                paper['Affiliations'].append(affiliation)\n",
    "        papers.append(paper)\n",
    "    return papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4b3d7",
   "metadata": {},
   "source": [
    "### Check Academic Affiliation\n",
    "The `check_academic` function determines if an affiliation is academic by matching keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650dd34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_academic(affiliation: str) -> bool:\n",
    "    academic_keywords = [\"school\", \"university\", \"college\", \"institute\", \"research\", \"lab\"]\n",
    "    affiliation = affiliation.translate(str.maketrans('', '', string.punctuation))\n",
    "    affiliation = affiliation.lower().split()\n",
    "    academic_keywords = set(academic_keywords)\n",
    "    affiliation = set(affiliation)\n",
    "    return len(academic_keywords.intersection(affiliation)) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f455c53",
   "metadata": {},
   "source": [
    "### Process Papers\n",
    "The `process_papers` function processes metadata and categorizes authors as academic or non-academic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b333b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_papers(papers: List[Dict]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for paper in papers:\n",
    "        non_academic_authors = []\n",
    "        affiliations = []\n",
    "        for author, affiliation in zip(paper['Authors'], paper['Affiliations']):\n",
    "            is_academic = check_academic(affiliation)\n",
    "            if not is_academic:\n",
    "                non_academic_authors.append(author)\n",
    "                affiliations.append(affiliation)\n",
    "        rows.append({\n",
    "            'PubmedID': paper['PubmedID'],\n",
    "            'Title': paper['Title'],\n",
    "            'Publication Date': paper['PublicationDate'],\n",
    "            'Non-academic Author(s)': \"; \".join(non_academic_authors),\n",
    "            'Company Affiliation(s)': \"; \".join(affiliations),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8dc698",
   "metadata": {},
   "source": [
    "\n",
    "## Example Usage\n",
    "\n",
    "The example demonstrates querying PubMed for papers and processing results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97d8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 100 IDs\n",
      "Fetched details for 10 papers\n",
      "0                                                     \n",
      "1                                                     \n",
      "2                                                     \n",
      "3                                                     \n",
      "4                                                     \n",
      "5     Zhe Zhao; Chang'e Liu; Qiuping Li; Xiaoyang Hong\n",
      "6    Hannes De Meulemeester; Frank De Smet; Johan v...\n",
      "7                                         Milan Špánik\n",
      "8                                         Xiaodong Luo\n",
      "9                                                     \n",
      "Name: Non-academic Author(s), dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Constants for PubMed API\n",
    "BASEURL_SRCH = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "BASEURL_FTCH = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'\n",
    "\n",
    "# Example query\n",
    "query = \"machine learning\"\n",
    "\n",
    "# Fetch PubMed IDs\n",
    "ids, query_key, web_env = fetch_paper_ids(query)\n",
    "print(f\"Fetched {len(ids)} IDs\")\n",
    "\n",
    "# Fetch details\n",
    "papers = fetch_paper_details(query_key, web_env)\n",
    "print(f\"Fetched details for {len(papers)} papers\")\n",
    "\n",
    "# Process papers\n",
    "df = process_papers(papers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78fe30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
